### RU202 - Redis Streams

[![alt RU202](img/RU202.JPG)](https://youtu.be/DEH2VVnpP5E)

[RU202 course GitHub repository](https://github.com/redislabs-training/ru202.git)


#### I. [Week1: Redis stream introduction](https://university.redis.io/course/cjoybtwksjmsjz/submodule/rww3gqqfg3h3mg/)

1. [RU202 CH01 1 Introduction to Distributed Systems](https://youtu.be/L-G6ZfM4ASU)
2. [Quiz 1 | Redis streams introduction](https://university.redis.io/course/cjoybtwksjmsjz/submodule/qiodmbbmt9hzlq/)
3. [RU202 CH01 3 Stream Processing](https://youtu.be/mFfksRQH9Qk)
4. [RU202 CH01 4 Stream Pipelines V05](https://youtu.be/dkLqij4pr68)
5. [Quiz 2 | Redis streams introduction](https://university.redis.io/course/cjoybtwksjmsjz/submodule/xlptmvcp12pzhx/)
6. [RU202 CH02 1 Overview of Redis Streams V04](https://youtu.be/0a9Uvx5EyD4)
7. [Quiz 3 | Redis streams introduction](https://university.redis.io/course/cjoybtwksjmsjz/submodule/uhrmzciprpv636/)
8. [RU202 CH02 3 Comparison V07](https://youtu.be/k6k6Hfqqwz0)
9. [Quiz 4 | Redis streams introduction](https://university.redis.io/course/cjoybtwksjmsjz/submodule/xbppkyza2kcw29/)
10. [RU202 CH02 5 working example V03](https://youtu.be/LNJ8evEdENA)
11. [Quiz 5 | Redis streams introduction](https://university.redis.io/course/cjoybtwksjmsjz/submodule/mqw4sqa0l3kqbj/)
12. [Hands-on activity](https://university.redis.io/course/cjoybtwksjmsjz/submodule/7wn2zsht7lw0ar/)
13. [Quiz 6 | Redis streams introduction](https://university.redis.io/course/cjoybtwksjmsjz/submodule/ayhtxtgpp8r6pz/)
14. [RU202 CH02 7 Week 1 Recap](https://youtu.be/NUA00AaxOTk)


#### II. [Week2: Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/1ofzi2getjh3g6/)

1. [RU202 CH05 0 Introduction to Week 2 V02](https://youtu.be/3LM6tBFBz1U)
2. [RU202 CH05 1 What Stream Producer V03](https://youtu.be/eWjhwvJeP38)
3. [RU202 CH05 2 Producer API](https://youtu.be/-kkA_aSdIs4)
4. [RU202 CH05 3 Message Identifier](https://youtu.be/TtsRO1viT0Q)
5. [Quiz 1 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/jrhgeazjlbxytv/)
6. [RU202 CH05 5 Message Payload V04](https://youtu.be/FVjQ421eJ0U)
7. [Quiz 2 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/frchdi5eovfjq9/)
8. [Managing the length of a stream](https://youtu.be/VBBb8IkDE4s)
9. [Quiz 3 | Redis stream producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/kmdlhalkx4cxl3/)
10. [RU202 CH06 1 Time-Based Range Queries](https://youtu.be/_558WNQneuU)
11. [Quiz 4 |Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/sbplnqltzxjihg/)
12. [RU202 CH06 3 Going back in time](https://youtu.be/615eJGdsVtA)
13. [Quiz 5 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/f4kh6i9uvvsz7o/)
14. [RU202 CH06 5 Reading a single message V02 1](https://youtu.be/sUoe2XxHp2U)
15. [Quiz 6 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/wqbcsqxvxqbj4t/)
16. [RU202 CH07 1 The Consumer](https://youtu.be/PoQT4TU6YhQ)
17. [Quiz 7 | Redis streams producers and](https://university.redis.io/course/52wyuazvxg07ov/submodule/huxnp2lqaevo0v/)
18. [RU202 CH07 3 The Blocking Consumer](https://youtu.be/3lqWdm4mv6U)
19. [Quiz 8 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/4eo1efgtctvqsh/)
20. [RU202 CH07 5 Concurrent Blocking Consumers V03](https://youtu.be/Isl-DE315vw)
21. [Quiz 9 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/ocdhyg0gqg31j7/)
22. [RU202 CH07 7 A Comparison to Pub Sub](https://youtu.be/gG0ZHE1JKNQ)
23. [Quiz 10 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/fw4ulvcnbhui55/)
24. [Quiz 11 | Redis streams producers and consumers](https://university.redis.io/course/52wyuazvxg07ov/submodule/wvubajmlxd0y4m/)
25. [RU202 CH07 9 Recap V02](https://youtu.be/Yh7oLbRzZIQ)


#### III. [Week3: Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/hfuxvllprn4dg4/)

1. [RU202 CH08 0 Week 3 Overview V02](https://youtu.be/x3s0HDU7Unc)
2. [RU202 CH08 1 The Problem with Slow Consumers V04](https://youtu.be/K8Z0TmRMTl4)
3. [Quiz 1 | Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/bn4u73uw7hesqu/)
4. [RU202 CH08 5 Consumer Groups V05](https://youtu.be/Npz_X6IYzCA)
5. [Quiz 2 | Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/atxreiojsgkvwh/)
6. [RU202 CH08 7 Consumer in a group V04](https://youtu.be/l-ODi0KShco)
7. [Quiz 3| Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/ajaykesp5hgjwk/)
8. [RU202 CH08 9 Processing in a Group V03](https://youtu.be/H4E5Eml-MIo)
9. [Quiz 4 | Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/numy4ucx69dfbm/)
10. [RU202 CH08 11 Disabling Acks V03](https://youtu.be/QhrxqW6U_QA)
11. [Quiz 5 | Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/qdwp31i2tz1f7b/)
12. [Hands-on activity: consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/po73y5ooqb3ead/)
13. [Running the code](https://university.redis.io/course/0fm00sidql5ksq/submodule/wzdcpukawty1st/)
14. [Redis CLI experiments](https://university.redis.io/course/0fm00sidql5ksq/submodule/ufkadhvo4gwmst/)
15. [Python code experiments](https://university.redis.io/course/0fm00sidql5ksq/submodule/4vpgy1l6ku3jlw/)
16. [Appendix: Code walkthrough](https://university.redis.io/course/0fm00sidql5ksq/submodule/e6ej1tlfpykz2u/)
17. [RU202 CH09 1 Basic consumer group admin V02](https://youtu.be/-0eXq_-BVQQ)
18. [XINFO GROUPs enhancements in Redis 7](https://university.redis.io/course/0fm00sidql5ksq/submodule/c520dqsoza82t5/)
19. [Quiz 6 | Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/pghvvonanlqxfu/)
20. [Quiz 7 | Redis streams consumer groups](https://university.redis.io/course/0fm00sidql5ksq/submodule/uly1q4uqhpksgs/)
21. [RU202 CH09 3 Week 3 Recap](https://youtu.be/yvWsa5MfojM)


#### IV. [Week4: Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/i1kpcuofd6p9mc/)

1. [RU202 CH010 1 Week 4 Intro V02](https://youtu.be/Zz6_KZEQNhI)
2. [RU202 CH010 2 Understanding XPENDING and XCLAIM V04](https://youtu.be/qeER8DkuZro)
3. [Quiz 1 | Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/ugaokbzoa5zenl/)
4. [RU202 CH010 3 Consumer Recovery V03](https://youtu.be/BHoTtrcgNwA)
5. [Quiz 2 | Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/vzoxwx5s1iiu28/)
6. [The XAUTOCLAIM command](https://university.redis.io/course/1s4guyphj5wim8/submodule/mgilqjww4zdxj0/)
7. [RU202 CH010 5 Performance Considerations V02](https://youtu.be/FxTcR05gyAI)
8. [Quiz 3 | Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/7ridpeio42xmnq/)
9. [RU202 CH010 6 Stream Memory Management V03](https://youtu.be/Cjgayjghpgs)
10. [Quiz 4 | Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/y38lskyzthyatb/)
11. [RU202 CH010 7 Stream Capping Strategies V05](https://youtu.be/o3FihimOEjY)
12. [Quiz 5 | Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/gdrdecj5df4mnn/)
13. [RU202 CH010 9 Redis Streams Usage Patterns V02](https://youtu.be/tkt6imYE09o)
14. [Quiz 6 | Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/qbp0zuaf9dzgmp/)
15. [Hands-on activity: introduction](https://university.redis.io/course/1s4guyphj5wim8/submodule/s4k39zhclyqota/)
16. [Running the producer](https://university.redis.io/course/1s4guyphj5wim8/submodule/r2aa5fndb3eje0/)
17. [Inspecting the dataset](https://university.redis.io/course/1s4guyphj5wim8/submodule/aakjjmlytjjjbl/)
18. [Running the consumers](https://university.redis.io/course/1s4guyphj5wim8/submodule/yrmpphmzl5qiz8/)
19. [Recovering a crashed consumer](https://university.redis.io/course/1s4guyphj5wim8/submodule/tocr6mrtbhkstw/)
20. [The hourly averages stream](https://university.redis.io/course/1s4guyphj5wim8/submodule/vo6vd4neisebvb/)
21. [Quiz 7 | Redis streams in production](https://university.redis.io/course/1s4guyphj5wim8/submodule/chvvmxbekhwr4t/)
22. [RU202 CH010 12 Week 4 Recap V01](https://youtu.be/nh3-H_7Lx_M)


#### V. [Week5: Redis streams final exam](https://university.redis.io/course/m6hicyzbkqvosb/submodule/curb3uali4eetk/)


#### VI. Appendix 
[Introduction to Redis streams](https://redis.io/docs/latest/develop/data-types/streams/)

- Adding an entry to a stream is O(1). Accessing any single entry is O(n), where n is the length of the ID. Since stream IDs are typically short and of a fixed length, this effectively reduces to a constant time lookup. 

- If you're running Redis 7 or later, you can also provide an explicit ID consisting of the milliseconds part only. In this case, the sequence portion of the ID will be automatically generated. 
```
XADD race:usa 0-* racer Prickett
```

- In this way, it is possible to scale the message processing across different consumers, without single consumers having to process all the messages: each consumer will just get different messages to process. This is basically what [Kafka&#8482;](https://kafka.apache.org/) does with consumer groups. Reading messages via consumer groups is yet another interesting mode of reading from a Redis Stream.

- however note that streams are replicated with fully specified XADD commands, so the replicas will have identical IDs to the master. 

- To continue the iteration with the next two items, I have to pick the last ID returned, that is 1692632094485-0, and add the prefix ( to it. The resulting exclusive range interval, that is (1692632094485-0 in this case, can now be used as the new start argument for the next XRANGE call:

- Since XRANGE complexity is O(log(N)) to seek, and then O(M) to return M elements, with a small count the command has a logarithmic time complexity, which means that each step of the iteration is fast. So XRANGE is also the de facto streams iterator and does not require an XSCAN command.

- Apart from the fact that XREAD can access multiple streams at once, and that we are able to specify the last ID we own to just get newer messages, in this simple form the command is not doing something so different compared to XRANGE. However, the interesting part is that we can turn XREAD into a blocking command easily, by specifying the BLOCK argument. 

- the special ID $. This special ID means that XREAD should use as last ID the maximum ID already stored in the stream mystream, so that we will receive only new messages, starting from the time we started listening. This is similar to the tail -f Unix command in some way.

- A consumer group tracks all the messages that are currently pending, that is, messages that were delivered to some consumer of the consumer group, but are yet to be acknowledged as processed. Thanks to this feature, when accessing the message history of a stream, each consumer *will only see messages that were delivered to it*.

- as a side effect, claiming a message will reset its idle time and will increment its number of deliveries counter. 

- Claiming may also be implemented by a separate process: one that just checks the list of pending messages, and assigns idle messages to consumers that appear to be active. Active consumers can be obtained using one of the observability features of Redis streams. 

- When there are failures, it is normal that messages will be delivered multiple times, but eventually they usually get processed and acknowledged. However there might be a problem processing some specific message, because it is corrupted or crafted in a way that triggers a bug in the processing code. In such a case what happens is that consumers will continuously fail to process this particular message. Because we have the counter of the delivery attempts, we can use that counter to detect messages that for some reason are not processable. So once the deliveries counter reaches a given large number that you chose, it is probably wiser to put such messages in another stream and send a notification to the system administrator. This is basically the way that Redis Streams implements the *dead letter* concept.

- 
What's new?
Quick starts
Client tools
Client APIs
Understand data types
Strings
JSON
Lists
Sets
Hashes
Sorted sets
Streams
Geospatial
Bitmaps
Bitfields
Probabilistic
Time series
Interact with data
Redis for AI
Use Redis
Reference
Libraries and tools
Redis products
Commands
DocsDocs
→
Develop with Redis
→
Understand Redis data types
→
Redis Streams
Redis Streams
Introduction to Redis streams

A Redis stream is a data structure that acts like an append-only log but also implements several operations to overcome some of the limits of a typical append-only log. These include random access in O(1) time and complex consumption strategies, such as consumer groups. You can use streams to record and simultaneously syndicate events in real time. Examples of Redis stream use cases include:

Event sourcing (e.g., tracking user actions, clicks, etc.)
Sensor monitoring (e.g., readings from devices in the field)
Notifications (e.g., storing a record of each user's notifications in a separate stream)
Redis generates a unique ID for each stream entry. You can use these IDs to retrieve their associated entries later or to read and process all subsequent entries in the stream. Note that because these IDs are related to time, the ones shown here may vary and will be different from the IDs you see in your own Redis instance.

Redis streams support several trimming strategies (to prevent streams from growing unbounded) and more than one consumption strategy (see XREAD, XREADGROUP, and XRANGE).

Basic commands
XADD adds a new entry to a stream.
XREAD reads one or more entries, starting at a given position and moving forward in time.
XRANGE returns a range of entries between two supplied entry IDs.
XLEN returns the length of a stream.
See the complete list of stream commands.

Examples
When our racers pass a checkpoint, we add a stream entry for each racer that includes the racer's name, speed, position, and location ID:


>_ Redis CLI
> XADD race:france * rider Castilla speed 30.2 position 1 location_id 1
"1692632086370-0"
> XADD race:france * rider Norem speed 28.8 position 3 location_id 1
"1692632094485-0"
> XADD race:france * rider Prickett speed 29.7 position 2 location_id 1
"1692632102976-0"


Python

Node.js

Java-Sync

Go

C#
Read two stream entries starting at ID 1692632086370-0:


>_ Redis CLI
> XRANGE race:france 1692632086370-0 + COUNT 2
1) 1) "1692632086370-0"
   2) 1) "rider"
      2) "Castilla"
      3) "speed"
      4) "30.2"
      5) "position"
      6) "1"
      7) "location_id"
      8) "1"
2) 1) "1692632094485-0"
   2) 1) "rider"
      2) "Norem"
      3) "speed"
      4) "28.8"
      5) "position"
      6) "3"
      7) "location_id"
      8) "1"


Python

Node.js

Java-Sync

Go

C#
Read up to 100 new stream entries, starting at the end of the stream, and block for up to 300 ms if no entries are being written:


>_ Redis CLI
> XREAD COUNT 100 BLOCK 300 STREAMS race:france $
(nil)


Python

Node.js

Java-Sync

Go

C#
Performance
Adding an entry to a stream is O(1). Accessing any single entry is O(n), where n is the length of the ID. Since stream IDs are typically short and of a fixed length, this effectively reduces to a constant time lookup. For details on why, note that streams are implemented as radix trees.

Simply put, Redis streams provide highly efficient inserts and reads. See each command's time complexity for the details.

Streams basics
Streams are an append-only data structure. The fundamental write command, called XADD, appends a new entry to the specified stream.

Each stream entry consists of one or more field-value pairs, somewhat like a dictionary or a Redis hash:


>_ Redis CLI
> XADD race:france * rider Castilla speed 29.9 position 1 location_id 2
"1692632147973-0"


Python

Node.js

Java-Sync

Go

C#
The above call to the XADD command adds an entry rider: Castilla, speed: 29.9, position: 1, location_id: 2 to the stream at key race:france, using an auto-generated entry ID, which is the one returned by the command, specifically 1692632147973-0. It gets as its first argument the key name race:france, the second argument is the entry ID that identifies every entry inside a stream. However, in this case, we passed * because we want the server to generate a new ID for us. Every new ID will be monotonically increasing, so in more simple terms, every new entry added will have a higher ID compared to all the past entries. Auto-generation of IDs by the server is almost always what you want, and the reasons for specifying an ID explicitly are very rare. We'll talk more about this later. The fact that each Stream entry has an ID is another similarity with log files, where line numbers, or the byte offset inside the file, can be used in order to identify a given entry. Returning back at our XADD example, after the key name and ID, the next arguments are the field-value pairs composing our stream entry.

It is possible to get the number of items inside a Stream just using the XLEN command:


>_ Redis CLI
> XLEN race:france
(integer) 4


Python

Node.js

Java-Sync

Go

C#
Entry IDs
The entry ID returned by the XADD command, and identifying univocally each entry inside a given stream, is composed of two parts:

<millisecondsTime>-<sequenceNumber>
The milliseconds time part is actually the local time in the local Redis node generating the stream ID, however if the current milliseconds time happens to be smaller than the previous entry time, then the previous entry time is used instead, so if a clock jumps backward the monotonically incrementing ID property still holds. The sequence number is used for entries created in the same millisecond. Since the sequence number is 64 bit wide, in practical terms there is no limit to the number of entries that can be generated within the same millisecond.

The format of such IDs may look strange at first, and the gentle reader may wonder why the time is part of the ID. The reason is that Redis streams support range queries by ID. Because the ID is related to the time the entry is generated, this gives the ability to query for time ranges basically for free. We will see this soon while covering the XRANGE command.

If for some reason the user needs incremental IDs that are not related to time but are actually associated to another external system ID, as previously mentioned, the XADD command can take an explicit ID instead of the * wildcard ID that triggers auto-generation, like in the following examples:


>_ Redis CLI
> XADD race:usa 0-1 racer Castilla
0-1
> XADD race:usa 0-2 racer Norem
0-2


Python

Node.js

Java-Sync

Go

C#
Note that in this case, the minimum ID is 0-1 and that the command will not accept an ID equal or smaller than a previous one:


>_ Redis CLI
> XADD race:usa 0-1 racer Prickett
(error) ERR The ID specified in XADD is equal or smaller than the target stream top item


Python

Node.js

Java-Sync

Go

C#
If you're running Redis 7 or later, you can also provide an explicit ID consisting of the milliseconds part only. In this case, the sequence portion of the ID will be automatically generated. To do this, use the syntax below:


>_ Redis CLI
> XADD race:usa 0-* racer Prickett
0-3


Python

Node.js

Java-Sync

Go

C#
Getting data from Streams
Now we are finally able to append entries in our stream via XADD. However, while appending data to a stream is quite obvious, the way streams can be queried in order to extract data is not so obvious. If we continue with the analogy of the log file, one obvious way is to mimic what we normally do with the Unix command tail -f, that is, we may start to listen in order to get the new messages that are appended to the stream. Note that unlike the blocking list operations of Redis, where a given element will reach a single client which is blocking in a pop style operation like BLPOP, with streams we want multiple consumers to see the new messages appended to the stream (the same way many tail -f processes can see what is added to a log). Using the traditional terminology we want the streams to be able to fan out messages to multiple clients.

However, this is just one potential access mode. We could also see a stream in quite a different way: not as a messaging system, but as a time series store. In this case, maybe it's also useful to get the new messages appended, but another natural query mode is to get messages by ranges of time, or alternatively to iterate the messages using a cursor to incrementally check all the history. This is definitely another useful access mode.

Finally, if we see a stream from the point of view of consumers, we may want to access the stream in yet another way, that is, as a stream of messages that can be partitioned to multiple consumers that are processing such messages, so that groups of consumers can only see a subset of the messages arriving in a single stream. In this way, it is possible to scale the message processing across different consumers, without single consumers having to process all the messages: each consumer will just get different messages to process. This is basically what Kafka (TM) does with consumer groups. Reading messages via consumer groups is yet another interesting mode of reading from a Redis Stream.

Redis Streams support all three of the query modes described above via different commands. The next sections will show them all, starting from the simplest and most direct to use: range queries.

Querying by range: XRANGE and XREVRANGE
To query the stream by range we are only required to specify two IDs, start and end. The range returned will include the elements having start or end as ID, so the range is inclusive. The two special IDs - and + respectively mean the smallest and the greatest ID possible.


>_ Redis CLI
> XRANGE race:france - +
1) 1) "1692632086370-0"
   2) 1) "rider"
      2) "Castilla"
      3) "speed"
      4) "30.2"
      5) "position"
      6) "1"
      7) "location_id"
      8) "1"
2) 1) "1692632094485-0"
   2) 1) "rider"
      2) "Norem"
      3) "speed"
      4) "28.8"
      5) "position"
      6) "3"
      7) "location_id"
      8) "1"
3) 1) "1692632102976-0"
   2) 1) "rider"
      2) "Prickett"
      3) "speed"
      4) "29.7"
      5) "position"
      6) "2"
      7) "location_id"
      8) "1"
4) 1) "1692632147973-0"
   2) 1) "rider"
      2) "Castilla"
      3) "speed"
      4) "29.9"
      5) "position"
      6) "1"
      7) "location_id"
      8) "2"


Python

Node.js

Java-Sync

Go

C#
Each entry returned is an array of two items: the ID and the list of field-value pairs. We already said that the entry IDs have a relation with the time, because the part at the left of the - character is the Unix time in milliseconds of the local node that created the stream entry, at the moment the entry was created (however note that streams are replicated with fully specified XADD commands, so the replicas will have identical IDs to the master). This means that I could query a range of time using XRANGE. In order to do so, however, I may want to omit the sequence part of the ID: if omitted, in the start of the range it will be assumed to be 0, while in the end part it will be assumed to be the maximum sequence number available. This way, querying using just two milliseconds Unix times, we get all the entries that were generated in that range of time, in an inclusive way. For instance, if I want to query a two milliseconds period I could use:


>_ Redis CLI
> XRANGE race:france 1692632086369 1692632086371
1) 1) "1692632086370-0"
   2) 1) "rider"
      2) "Castilla"
      3) "speed"
      4) "30.2"
      5) "position"
      6) "1"
      7) "location_id"
      8) "1"


Python

Node.js

Java-Sync

Go

C#
I have only a single entry in this range. However in real data sets, I could query for ranges of hours, or there could be many items in just two milliseconds, and the result returned could be huge. For this reason, XRANGE supports an optional COUNT option at the end. By specifying a count, I can just get the first N items. If I want more, I can get the last ID returned, increment the sequence part by one, and query again. Let's see this in the following example. Let's assume that the stream race:france was populated with 4 items. To start my iteration, getting 2 items per command, I start with the full range, but with a count of 2.


>_ Redis CLI
> XRANGE race:france - + COUNT 2
1) 1) "1692632086370-0"
   2) 1) "rider"
      2) "Castilla"
      3) "speed"
      4) "30.2"
      5) "position"
      6) "1"
      7) "location_id"
      8) "1"
2) 1) "1692632094485-0"
   2) 1) "rider"
      2) "Norem"
      3) "speed"
      4) "28.8"
      5) "position"
      6) "3"
      7) "location_id"
      8) "1"


Python

Node.js

Java-Sync

Go

C#
To continue the iteration with the next two items, I have to pick the last ID returned, that is 1692632094485-0, and add the prefix ( to it. The resulting exclusive range interval, that is (1692632094485-0 in this case, can now be used as the new start argument for the next XRANGE call:


>_ Redis CLI
> XRANGE race:france (1692632094485-0 + COUNT 2
1) 1) "1692632102976-0"
   2) 1) "rider"
      2) "Prickett"
      3) "speed"
      4) "29.7"
      5) "position"
      6) "2"
      7) "location_id"
      8) "1"
2) 1) "1692632147973-0"
   2) 1) "rider"
      2) "Castilla"
      3) "speed"
      4) "29.9"
      5) "position"
      6) "1"
      7) "location_id"
      8) "2"


Python

Node.js

Java-Sync

Go

C#
Now that we've retrieved 4 items out of a stream that only had 4 entries in it, if we try to retrieve more items, we'll get an empty array:


>_ Redis CLI
> XRANGE race:france (1692632147973-0 + COUNT 2
(empty array)


Python

Node.js

Java-Sync

Go

C#
Since XRANGE complexity is O(log(N)) to seek, and then O(M) to return M elements, with a small count the command has a logarithmic time complexity, which means that each step of the iteration is fast. So XRANGE is also the de facto streams iterator and does not require an XSCAN command.

The command XREVRANGE is the equivalent of XRANGE but returning the elements in inverted order, so a practical use for XREVRANGE is to check what is the last item in a Stream:


>_ Redis CLI
> XREVRANGE race:france + - COUNT 1
1) 1) "1692632147973-0"
   2) 1) "rider"
      2) "Castilla"
      3) "speed"
      4) "29.9"
      5) "position"
      6) "1"
      7) "location_id"
      8) "2"


Python

Node.js

Java-Sync

Go

C#
Note that the XREVRANGE command takes the start and stop arguments in reverse order.

Listening for new items with XREAD
When we do not want to access items by a range in a stream, usually what we want instead is to subscribe to new items arriving to the stream. This concept may appear related to Redis Pub/Sub, where you subscribe to a channel, or to Redis blocking lists, where you wait for a key to get new elements to fetch, but there are fundamental differences in the way you consume a stream:

A stream can have multiple clients (consumers) waiting for data. Every new item, by default, will be delivered to every consumer that is waiting for data in a given stream. This behavior is different than blocking lists, where each consumer will get a different element. However, the ability to fan out to multiple consumers is similar to Pub/Sub.
While in Pub/Sub messages are fire and forget and are never stored anyway, and while when using blocking lists, when a message is received by the client it is popped (effectively removed) from the list, streams work in a fundamentally different way. All the messages are appended in the stream indefinitely (unless the user explicitly asks to delete entries): different consumers will know what is a new message from its point of view by remembering the ID of the last message received.
Streams Consumer Groups provide a level of control that Pub/Sub or blocking lists cannot achieve, with different groups for the same stream, explicit acknowledgment of processed items, ability to inspect the pending items, claiming of unprocessed messages, and coherent history visibility for each single client, that is only able to see its private past history of messages.
The command that provides the ability to listen for new messages arriving into a stream is called XREAD. It's a bit more complex than XRANGE, so we'll start showing simple forms, and later the whole command layout will be provided.


>_ Redis CLI
> XREAD COUNT 2 STREAMS race:france 0
1) 1) "race:france"
   2) 1) 1) "1692632086370-0"
         2) 1) "rider"
            2) "Castilla"
            3) "speed"
            4) "30.2"
            5) "position"
            6) "1"
            7) "location_id"
            8) "1"
      2) 1) "1692632094485-0"
         2) 1) "rider"
            2) "Norem"
            3) "speed"
            4) "28.8"
            5) "position"
            6) "3"
            7) "location_id"
            8) "1"


Python

Node.js

Java-Sync

Go

C#
The above is the non-blocking form of XREAD. Note that the COUNT option is not mandatory, in fact the only mandatory option of the command is the STREAMS option, that specifies a list of keys together with the corresponding maximum ID already seen for each stream by the calling consumer, so that the command will provide the client only with messages with an ID greater than the one we specified.

In the above command we wrote STREAMS race:france 0 so we want all the messages in the Stream race:france having an ID greater than 0-0. As you can see in the example above, the command returns the key name, because actually it is possible to call this command with more than one key to read from different streams at the same time. I could write, for instance: STREAMS race:france race:italy 0 0. Note how after the STREAMS option we need to provide the key names, and later the IDs. For this reason, the STREAMS option must always be the last option. Any other options must come before the STREAMS option.

Apart from the fact that XREAD can access multiple streams at once, and that we are able to specify the last ID we own to just get newer messages, in this simple form the command is not doing something so different compared to XRANGE. However, the interesting part is that we can turn XREAD into a blocking command easily, by specifying the BLOCK argument:

> XREAD BLOCK 0 STREAMS race:france $
Note that in the example above, other than removing COUNT, I specified the new BLOCK option with a timeout of 0 milliseconds (that means to never timeout). Moreover, instead of passing a normal ID for the stream mystream I passed the special ID $. This special ID means that XREAD should use as last ID the maximum ID already stored in the stream mystream, so that we will receive only new messages, starting from the time we started listening. This is similar to the tail -f Unix command in some way.

Note that when the BLOCK option is used, we do not have to use the special ID $. We can use any valid ID. If the command is able to serve our request immediately without blocking, it will do so, otherwise it will block. Normally if we want to consume the stream starting from new entries, we start with the ID $, and after that we continue using the ID of the last message received to make the next call, and so forth.

The blocking form of XREAD is also able to listen to multiple Streams, just by specifying multiple key names. If the request can be served synchronously because there is at least one stream with elements greater than the corresponding ID we specified, it returns with the results. Otherwise, the command will block and will return the items of the first stream which gets new data (according to the specified ID).

Similarly to blocking list operations, blocking stream reads are fair from the point of view of clients waiting for data, since the semantics is FIFO style. The first client that blocked for a given stream will be the first to be unblocked when new items are available.

XREAD has no other options than COUNT and BLOCK, so it's a pretty basic command with a specific purpose to attach consumers to one or multiple streams. More powerful features to consume streams are available using the consumer groups API, however reading via consumer groups is implemented by a different command called XREADGROUP, covered in the next section of this guide.

Consumer groups
When the task at hand is to consume the same stream from different clients, then XREAD already offers a way to fan-out to N clients, potentially also using replicas in order to provide more read scalability. However in certain problems what we want to do is not to provide the same stream of messages to many clients, but to provide a different subset of messages from the same stream to many clients. An obvious case where this is useful is that of messages which are slow to process: the ability to have N different workers that will receive different parts of the stream allows us to scale message processing, by routing different messages to different workers that are ready to do more work.

In practical terms, if we imagine having three consumers C1, C2, C3, and a stream that contains the messages 1, 2, 3, 4, 5, 6, 7 then what we want is to serve the messages according to the following diagram:

1 -> C1
2 -> C2
3 -> C3
4 -> C1
5 -> C2
6 -> C3
7 -> C1
In order to achieve this, Redis uses a concept called consumer groups. It is very important to understand that Redis consumer groups have nothing to do, from an implementation standpoint, with Kafka (TM) consumer groups. Yet they are similar in functionality, so I decided to keep Kafka's (TM) terminology, as it originally popularized this idea.

A consumer group is like a pseudo consumer that gets data from a stream, and actually serves multiple consumers, providing certain guarantees:

Each message is served to a different consumer so that it is not possible that the same message will be delivered to multiple consumers.
Consumers are identified, within a consumer group, by a name, which is a case-sensitive string that the clients implementing consumers must choose. This means that even after a disconnect, the stream consumer group retains all the state, since the client will claim again to be the same consumer. However, this also means that it is up to the client to provide a unique identifier.
Each consumer group has the concept of the first ID never consumed so that, when a consumer asks for new messages, it can provide just messages that were not previously delivered.
Consuming a message, however, requires an explicit acknowledgment using a specific command. Redis interprets the acknowledgment as: this message was correctly processed so it can be evicted from the consumer group.
A consumer group tracks all the messages that are currently pending, that is, messages that were delivered to some consumer of the consumer group, but are yet to be acknowledged as processed. Thanks to this feature, when accessing the message history of a stream, each consumer will only see messages that were delivered to it.
In a way, a consumer group can be imagined as some amount of state about a stream:

+----------------------------------------+
| consumer_group_name: mygroup           |
| consumer_group_stream: somekey         |
| last_delivered_id: 1292309234234-92    |
|                                        |
| consumers:                             |
|    "consumer-1" with pending messages  |
|       1292309234234-4                  |
|       1292309234232-8                  |
|    "consumer-42" with pending messages |
|       ... (and so forth)               |
+----------------------------------------+
If you see this from this point of view, it is very simple to understand what a consumer group can do, how it is able to just provide consumers with their history of pending messages, and how consumers asking for new messages will just be served with message IDs greater than last_delivered_id. At the same time, if you look at the consumer group as an auxiliary data structure for Redis streams, it is obvious that a single stream can have multiple consumer groups, that have a different set of consumers. Actually, it is even possible for the same stream to have clients reading without consumer groups via XREAD, and clients reading via XREADGROUP in different consumer groups.

Now it's time to zoom in to see the fundamental consumer group commands. They are the following:

XGROUP is used in order to create, destroy and manage consumer groups.
XREADGROUP is used to read from a stream via a consumer group.
XACK is the command that allows a consumer to mark a pending message as correctly processed.
Creating a consumer group
Assuming I have a key race:france of type stream already existing, in order to create a consumer group I just need to do the following:


>_ Redis CLI
> XGROUP CREATE race:france france_riders $
OK


Python

Node.js

Java-Sync

Go

C#
As you can see in the command above when creating the consumer group we have to specify an ID, which in the example is just $. This is needed because the consumer group, among the other states, must have an idea about what message to serve next at the first consumer connecting, that is, what was the last message ID when the group was just created. If we provide $ as we did, then only new messages arriving in the stream from now on will be provided to the consumers in the group. If we specify 0 instead the consumer group will consume all the messages in the stream history to start with. Of course, you can specify any other valid ID. What you know is that the consumer group will start delivering messages that are greater than the ID you specify. Because $ means the current greatest ID in the stream, specifying $ will have the effect of consuming only new messages.

XGROUP CREATE also supports creating the stream automatically, if it doesn't exist, using the optional MKSTREAM subcommand as the last argument:


>_ Redis CLI
> XGROUP CREATE race:italy italy_riders $ MKSTREAM
OK


Python

Node.js

Java-Sync

Go

C#
Now that the consumer group is created we can immediately try to read messages via the consumer group using the XREADGROUP command. We'll read from consumers, that we will call Alice and Bob, to see how the system will return different messages to Alice or Bob.

XREADGROUP is very similar to XREAD and provides the same BLOCK option, otherwise it is a synchronous command. However there is a mandatory option that must be always specified, which is GROUP and has two arguments: the name of the consumer group, and the name of the consumer that is attempting to read. The option COUNT is also supported and is identical to the one in XREAD.

We'll add riders to the race:italy stream and try reading something using the consumer group: Note: here rider is the field name, and the name is the associated value. Remember that stream items are small dictionaries.


>_ Redis CLI
> XADD race:italy * rider Castilla
"1692632639151-0"
> XADD race:italy * rider Royce
"1692632647899-0"
> XADD race:italy * rider Sam-Bodden
"1692632662819-0"
> XADD race:italy * rider Prickett
"1692632670501-0"
> XADD race:italy * rider Norem
"1692632678249-0"
> XREADGROUP GROUP italy_riders Alice COUNT 1 STREAMS race:italy >
1) 1) "race:italy"
   2) 1) 1) "1692632639151-0"
         2) 1) "rider"
            2) "Castilla"


Python

Node.js

Java-Sync

Go

C#
XREADGROUP replies are just like XREAD replies. Note however the GROUP <group-name> <consumer-name> provided above. It states that I want to read from the stream using the consumer group mygroup and I'm the consumer Alice. Every time a consumer performs an operation with a consumer group, it must specify its name, uniquely identifying this consumer inside the group.

There is another very important detail in the command line above, after the mandatory STREAMS option the ID requested for the key mystream is the special ID >. This special ID is only valid in the context of consumer groups, and it means: messages never delivered to other consumers so far.

This is almost always what you want, however it is also possible to specify a real ID, such as 0 or any other valid ID, in this case, however, what happens is that we request from XREADGROUP to just provide us with the history of pending messages, and in such case, will never see new messages in the group. So basically XREADGROUP has the following behavior based on the ID we specify:

If the ID is the special ID > then the command will return only new messages never delivered to other consumers so far, and as a side effect, will update the consumer group's last ID.
If the ID is any other valid numerical ID, then the command will let us access our history of pending messages. That is, the set of messages that were delivered to this specified consumer (identified by the provided name), and never acknowledged so far with XACK.
We can test this behavior immediately specifying an ID of 0, without any COUNT option: we'll just see the only pending message, that is, the one about Castilla:


>_ Redis CLI
> XREADGROUP GROUP italy_riders Alice STREAMS race:italy 0
1) 1) "race:italy"
   2) 1) 1) "1692632639151-0"
         2) 1) "rider"
            2) "Castilla"


Python

Node.js

Java-Sync

Go

C#
However, if we acknowledge the message as processed, it will no longer be part of the pending messages history, so the system will no longer report anything:


>_ Redis CLI
> XACK race:italy italy_riders 1692632639151-0
(integer) 1
> XREADGROUP GROUP italy_riders Alice STREAMS race:italy 0
1) 1) "race:italy"
   2) (empty array)


Python

Node.js

Java-Sync

Go

C#
Don't worry if you yet don't know how XACK works, the idea is just that processed messages are no longer part of the history that we can access.

Now it's Bob's turn to read something:


>_ Redis CLI
> XREADGROUP GROUP italy_riders Bob COUNT 2 STREAMS race:italy >
1) 1) "race:italy"
   2) 1) 1) "1692632647899-0"
         2) 1) "rider"
            2) "Royce"
      2) 1) "1692632662819-0"
         2) 1) "rider"
            2) "Sam-Bodden"


Python

Node.js

Java-Sync

Go

C#
Bob asked for a maximum of two messages and is reading via the same group mygroup. So what happens is that Redis reports just new messages. As you can see the "Castilla" message is not delivered, since it was already delivered to Alice, so Bob gets Royce and Sam-Bodden and so forth.

This way Alice, Bob, and any other consumer in the group, are able to read different messages from the same stream, to read their history of yet to process messages, or to mark messages as processed. This allows creating different topologies and semantics for consuming messages from a stream.

There are a few things to keep in mind:

Consumers are auto-created the first time they are mentioned, no need for explicit creation.
Even with XREADGROUP you can read from multiple keys at the same time, however for this to work, you need to create a consumer group with the same name in every stream. This is not a common need, but it is worth mentioning that the feature is technically available.
XREADGROUP is a write command because even if it reads from the stream, the consumer group is modified as a side effect of reading, so it can only be called on master instances.
An example of a consumer implementation, using consumer groups, written in the Ruby language could be the following. The Ruby code is aimed to be readable by virtually any experienced programmer, even if they do not know Ruby:

require 'redis'

if ARGV.length == 0
    puts "Please specify a consumer name"
    exit 1
end

ConsumerName = ARGV[0]
GroupName = "mygroup"
r = Redis.new

def process_message(id,msg)
    puts "[#{ConsumerName}] #{id} = #{msg.inspect}"
end

$lastid = '0-0'

puts "Consumer #{ConsumerName} starting..."
check_backlog = true
while true
    # Pick the ID based on the iteration: the first time we want to
    # read our pending messages, in case we crashed and are recovering.
    # Once we consumed our history, we can start getting new messages.
    if check_backlog
        myid = $lastid
    else
        myid = '>'
    end

    items = r.xreadgroup('GROUP',GroupName,ConsumerName,'BLOCK','2000','COUNT','10','STREAMS',:my_stream_key,myid)

    if items == nil
        puts "Timeout!"
        next
    end

    # If we receive an empty reply, it means we were consuming our history
    # and that the history is now empty. Let's start to consume new messages.
    check_backlog = false if items[0][1].length == 0

    items[0][1].each{|i|
        id,fields = i

        # Process the message
        process_message(id,fields)

        # Acknowledge the message as processed
        r.xack(:my_stream_key,GroupName,id)

        $lastid = id
    }
end
As you can see the idea here is to start by consuming the history, that is, our list of pending messages. This is useful because the consumer may have crashed before, so in the event of a restart we want to re-read messages that were delivered to us without getting acknowledged. Note that we might process a message multiple times or one time (at least in the case of consumer failures, but there are also the limits of Redis persistence and replication involved, see the specific section about this topic).

Once the history was consumed, and we get an empty list of messages, we can switch to using the > special ID in order to consume new messages.

Recovering from permanent failures
The example above allows us to write consumers that participate in the same consumer group, each taking a subset of messages to process, and when recovering from failures re-reading the pending messages that were delivered just to them. However in the real world consumers may permanently fail and never recover. What happens to the pending messages of the consumer that never recovers after stopping for any reason?

Redis consumer groups offer a feature that is used in these situations in order to claim the pending messages of a given consumer so that such messages will change ownership and will be re-assigned to a different consumer. The feature is very explicit. A consumer has to inspect the list of pending messages, and will have to claim specific messages using a special command, otherwise the server will leave the messages pending forever and assigned to the old consumer. In this way different applications can choose if to use such a feature or not, and exactly how to use it.

The first step of this process is just a command that provides observability of pending entries in the consumer group and is called XPENDING. This is a read-only command which is always safe to call and will not change ownership of any message. In its simplest form, the command is called with two arguments, which are the name of the stream and the name of the consumer group.


>_ Redis CLI
> XPENDING race:italy italy_riders
1) (integer) 2
2) "1692632647899-0"
3) "1692632662819-0"
4) 1) 1) "Bob"
      2) "2"


Python

Node.js

Java-Sync

Go

C#
When called in this way, the command outputs the total number of pending messages in the consumer group (two in this case), the lower and higher message ID among the pending messages, and finally a list of consumers and the number of pending messages they have. We have only Bob with two pending messages because the single message that Alice requested was acknowledged using XACK.

We can ask for more information by giving more arguments to XPENDING, because the full command signature is the following:

XPENDING <key> <groupname> [[IDLE <min-idle-time>] <start-id> <end-id> <count> [<consumer-name>]]
By providing a start and end ID (that can be just - and + as in XRANGE) and a count to control the amount of information returned by the command, we are able to know more about the pending messages. The optional final argument, the consumer name, is used if we want to limit the output to just messages pending for a given consumer, but won't use this feature in the following example.


>_ Redis CLI
> XPENDING race:italy italy_riders - + 10
1) 1) "1692632647899-0"
   2) "Bob"
   3) (integer) 74642
   4) (integer) 1
2) 1) "1692632662819-0"
   2) "Bob"
   3) (integer) 74642
   4) (integer) 1


Python

Node.js

Java-Sync

Go

C#
Now we have the details for each message: the ID, the consumer name, the idle time in milliseconds, which is how many milliseconds have passed since the last time the message was delivered to some consumer, and finally the number of times that a given message was delivered. We have two messages from Bob, and they are idle for 60000+ milliseconds, about a minute.

Note that nobody prevents us from checking what the first message content was by just using XRANGE.


>_ Redis CLI
> XRANGE race:italy 1692632647899-0 1692632647899-0
1) 1) "1692632647899-0"
   2) 1) "rider"
      2) "Royce"


Python

Node.js

Java-Sync

Go

C#
We have just to repeat the same ID twice in the arguments. Now that we have some ideas, Alice may decide that after 1 minute of not processing messages, Bob will probably not recover quickly, and it's time to claim such messages and resume the processing in place of Bob. To do so, we use the XCLAIM command.

This command is very complex and full of options in its full form, since it is used for replication of consumer groups changes, but we'll use just the arguments that we need normally. In this case it is as simple as:

XCLAIM <key> <group> <consumer> <min-idle-time> <ID-1> <ID-2> ... <ID-N>
Basically we say, for this specific key and group, I want that the message IDs specified will change ownership, and will be assigned to the specified consumer name <consumer>. However, we also provide a minimum idle time, so that the operation will only work if the idle time of the mentioned messages is greater than the specified idle time. This is useful because maybe two clients are retrying to claim a message at the same time:

Client 1: XCLAIM race:italy italy_riders Alice 60000 1692632647899-0
Client 2: XCLAIM race:italy italy_riders Lora 60000 1692632647899-0
However, as a side effect, claiming a message will reset its idle time and will increment its number of deliveries counter, so the second client will fail claiming it. In this way we avoid trivial re-processing of messages (even if in the general case you cannot obtain exactly once processing).

This is the result of the command execution:


>_ Redis CLI
> XCLAIM race:italy italy_riders Alice 60000 1692632647899-0
1) 1) "1692632647899-0"
   2) 1) "rider"
      2) "Royce"


Python

Node.js

Java-Sync

Go

C#
The message was successfully claimed by Alice, who can now process the message and acknowledge it, and move things forward even if the original consumer is not recovering.

It is clear from the example above that as a side effect of successfully claiming a given message, the XCLAIM command also returns it. However this is not mandatory. The JUSTID option can be used in order to return just the IDs of the message successfully claimed. This is useful if you want to reduce the bandwidth used between the client and the server (and also the performance of the command) and you are not interested in the message because your consumer is implemented in a way that it will rescan the history of pending messages from time to time.

Claiming may also be implemented by a separate process: one that just checks the list of pending messages, and assigns idle messages to consumers that appear to be active. Active consumers can be obtained using one of the observability features of Redis streams. This is the topic of the next section.

Automatic claiming
The XAUTOCLAIM command, added in Redis 6.2, implements the claiming process that we've described above. XPENDING and XCLAIM provide the basic building blocks for different types of recovery mechanisms. This command optimizes the generic process by having Redis manage it and offers a simple solution for most recovery needs.

XAUTOCLAIM identifies idle pending messages and transfers ownership of them to a consumer. The command's signature looks like this:

XAUTOCLAIM <key> <group> <consumer> <min-idle-time> <start> [COUNT count] [JUSTID]
So, in the example above, I could have used automatic claiming to claim a single message like this:


>_ Redis CLI
> XAUTOCLAIM race:italy italy_riders Alice 60000 0-0 COUNT 1
1) "0-0"
2) 1) 1) "1692632662819-0"
      2) 1) "rider"
         2) "Sam-Bodden"


Python

Node.js

Java-Sync

Go

C#
Like XCLAIM, the command replies with an array of the claimed messages, but it also returns a stream ID that allows iterating the pending entries. The stream ID is a cursor, and I can use it in my next call to continue in claiming idle pending messages:


>_ Redis CLI
> XAUTOCLAIM race:italy italy_riders Lora 60000 (1692632662819-0 COUNT 1
1) "1692632662819-0"
2) 1) 1) "1692632647899-0"
      2) 1) "rider"
         2) "Royce"


Python

Node.js

Java-Sync

Go

C#
When XAUTOCLAIM returns the "0-0" stream ID as a cursor, that means that it reached the end of the consumer group pending entries list. That doesn't mean that there are no new idle pending messages, so the process continues by calling XAUTOCLAIM from the beginning of the stream.

Claiming and the delivery counter
The counter that you observe in the XPENDING output is the number of deliveries of each message. The counter is incremented in two ways: when a message is successfully claimed via XCLAIM or when an XREADGROUP call is used in order to access the history of pending messages.

When there are failures, it is normal that messages will be delivered multiple times, but eventually they usually get processed and acknowledged. However there might be a problem processing some specific message, because it is corrupted or crafted in a way that triggers a bug in the processing code. In such a case what happens is that consumers will continuously fail to process this particular message. Because we have the counter of the delivery attempts, we can use that counter to detect messages that for some reason are not processable. So once the deliveries counter reaches a given large number that you chose, it is probably wiser to put such messages in another stream and send a notification to the system administrator. This is basically the way that Redis Streams implements the dead letter concept.

- Messaging systems that lack observability are very hard to work with. 

- So basically Kafka partitions are more similar to using N different Redis keys, while Redis consumer groups are a server-side load balancing system of messages from a given stream to N different consumers.

- However trimming with MAXLEN can be expensive: streams are represented by macro nodes into a radix tree, in order to be very memory efficient. Altering the single macro node, consisting of a few tens of elements, is not optimal. 

- However in the current implementation, memory is not really reclaimed until a macro node is completely empty, so you should not abuse this feature.

- Streams, on the other hand, are allowed to stay at zero elements, both as a result of using a MAXLEN option with a count of zero (XADD and XTRIM commands), or because XDEL was called.

- The reason why such an asymmetry exists is because Streams may have associated consumer groups, and we do not want to lose the state that the consumer groups defined just because there are no longer any items in the stream. Currently the stream is not deleted even when it has no associated consumer groups.

- It should be enough to say that stream commands are at least as fast as sorted set commands when extracting ranges, and that XADD is very fast and can easily insert from half a million to one million items per second in an average machine if pipelining is used.

### EOF (2025/01/10)
